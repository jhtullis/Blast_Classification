{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba26fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from warnings import filterwarnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2922f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter warnings from numpy that show up occasionally during cv, should not affect performance\n",
    "filterwarnings(\"ignore\", message=\"invalid value encountered in cast\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4d4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "# extract data from file\n",
    "excel_file = \"../Data/Cell_Data.xlsx\"\n",
    "sheets_dict = pd.read_excel(excel_file, sheet_name = None) # dict where each value is a data frame (sheet)\n",
    "\n",
    "# cell type labels are sheet labels in the excel document and keys in the df dict\n",
    "# cell_types = ['L1', 'L2', 'L3', 'Monoblasts', 'Myeloblasts', 'Reactive Lymphs']\n",
    "cell_types = list(sheets_dict.keys())\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    # add a cell type column to each data frame\n",
    "    sheets_dict[cell_type][\"cell_type\"] = cell_type\n",
    "\n",
    "# build one singular df with a class column identifying cell_type\n",
    "df_list = [sheets_dict[cell_type] for cell_type in cell_types]\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# throw out name of image, area, and total image area\n",
    "combined_df.drop([\"Image\", \"Area (microns^2)\", \"TotalImageArea\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815139c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lacunarity</th>\n",
       "      <th>Total Length (microns)</th>\n",
       "      <th>Endpoints</th>\n",
       "      <th>HGU (microns)</th>\n",
       "      <th>Branchpoints</th>\n",
       "      <th>Box-Counting Fractal Dimension</th>\n",
       "      <th>Curvature_50.0</th>\n",
       "      <th>% High Density Matrix</th>\n",
       "      <th>Alignment</th>\n",
       "      <th>Branchpoints/Total Length</th>\n",
       "      <th>Endpoints/Total Length</th>\n",
       "      <th>Average Fiber Length</th>\n",
       "      <th>Average Fiber Thickness</th>\n",
       "      <th>cell_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.211</td>\n",
       "      <td>4005</td>\n",
       "      <td>69</td>\n",
       "      <td>58.043</td>\n",
       "      <td>367</td>\n",
       "      <td>1.175</td>\n",
       "      <td>26.812</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.11620</td>\n",
       "      <td>0.091635</td>\n",
       "      <td>0.017228</td>\n",
       "      <td>18.371560</td>\n",
       "      <td>14.656679</td>\n",
       "      <td>L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.888</td>\n",
       "      <td>3485</td>\n",
       "      <td>90</td>\n",
       "      <td>38.722</td>\n",
       "      <td>227</td>\n",
       "      <td>1.112</td>\n",
       "      <td>36.987</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.06317</td>\n",
       "      <td>0.065136</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>21.987382</td>\n",
       "      <td>16.011478</td>\n",
       "      <td>L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173.399</td>\n",
       "      <td>1880</td>\n",
       "      <td>43</td>\n",
       "      <td>43.721</td>\n",
       "      <td>59</td>\n",
       "      <td>1.024</td>\n",
       "      <td>30.577</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.09171</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>36.862745</td>\n",
       "      <td>28.829787</td>\n",
       "      <td>L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.193</td>\n",
       "      <td>3203</td>\n",
       "      <td>59</td>\n",
       "      <td>54.288</td>\n",
       "      <td>161</td>\n",
       "      <td>1.115</td>\n",
       "      <td>24.991</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.03657</td>\n",
       "      <td>0.050265</td>\n",
       "      <td>0.018420</td>\n",
       "      <td>29.118182</td>\n",
       "      <td>19.419294</td>\n",
       "      <td>L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.483</td>\n",
       "      <td>2414</td>\n",
       "      <td>54</td>\n",
       "      <td>44.704</td>\n",
       "      <td>82</td>\n",
       "      <td>1.088</td>\n",
       "      <td>26.482</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.05596</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>0.022370</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>23.819387</td>\n",
       "      <td>L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>86.239</td>\n",
       "      <td>3993</td>\n",
       "      <td>99</td>\n",
       "      <td>40.333</td>\n",
       "      <td>80</td>\n",
       "      <td>1.110</td>\n",
       "      <td>34.130</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.03727</td>\n",
       "      <td>0.020035</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>44.614525</td>\n",
       "      <td>16.403706</td>\n",
       "      <td>Reactive Lymphs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>124.097</td>\n",
       "      <td>2777</td>\n",
       "      <td>61</td>\n",
       "      <td>45.525</td>\n",
       "      <td>88</td>\n",
       "      <td>1.097</td>\n",
       "      <td>39.728</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.10080</td>\n",
       "      <td>0.031689</td>\n",
       "      <td>0.021966</td>\n",
       "      <td>37.275168</td>\n",
       "      <td>19.877566</td>\n",
       "      <td>Reactive Lymphs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>76.126</td>\n",
       "      <td>3913</td>\n",
       "      <td>65</td>\n",
       "      <td>60.200</td>\n",
       "      <td>126</td>\n",
       "      <td>1.148</td>\n",
       "      <td>33.045</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.07569</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>40.973822</td>\n",
       "      <td>19.039100</td>\n",
       "      <td>Reactive Lymphs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>75.398</td>\n",
       "      <td>4100</td>\n",
       "      <td>58</td>\n",
       "      <td>70.690</td>\n",
       "      <td>138</td>\n",
       "      <td>1.170</td>\n",
       "      <td>27.441</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.03438</td>\n",
       "      <td>0.033659</td>\n",
       "      <td>0.014146</td>\n",
       "      <td>41.836735</td>\n",
       "      <td>18.024390</td>\n",
       "      <td>Reactive Lymphs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>90.529</td>\n",
       "      <td>4475</td>\n",
       "      <td>56</td>\n",
       "      <td>79.911</td>\n",
       "      <td>102</td>\n",
       "      <td>1.153</td>\n",
       "      <td>37.669</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.022793</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>56.645570</td>\n",
       "      <td>14.569832</td>\n",
       "      <td>Reactive Lymphs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2600 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lacunarity  Total Length (microns)  Endpoints  HGU (microns)  \\\n",
       "0         79.211                    4005         69         58.043   \n",
       "1        110.888                    3485         90         38.722   \n",
       "2        173.399                    1880         43         43.721   \n",
       "3         96.193                    3203         59         54.288   \n",
       "4        132.483                    2414         54         44.704   \n",
       "...          ...                     ...        ...            ...   \n",
       "2595      86.239                    3993         99         40.333   \n",
       "2596     124.097                    2777         61         45.525   \n",
       "2597      76.126                    3913         65         60.200   \n",
       "2598      75.398                    4100         58         70.690   \n",
       "2599      90.529                    4475         56         79.911   \n",
       "\n",
       "      Branchpoints  Box-Counting Fractal Dimension  Curvature_50.0  \\\n",
       "0              367                           1.175          26.812   \n",
       "1              227                           1.112          36.987   \n",
       "2               59                           1.024          30.577   \n",
       "3              161                           1.115          24.991   \n",
       "4               82                           1.088          26.482   \n",
       "...            ...                             ...             ...   \n",
       "2595            80                           1.110          34.130   \n",
       "2596            88                           1.097          39.728   \n",
       "2597           126                           1.148          33.045   \n",
       "2598           138                           1.170          27.441   \n",
       "2599           102                           1.153          37.669   \n",
       "\n",
       "      % High Density Matrix  Alignment  Branchpoints/Total Length  \\\n",
       "0                     0.587    0.11620                   0.091635   \n",
       "1                     0.558    0.06317                   0.065136   \n",
       "2                     0.542    0.09171                   0.031383   \n",
       "3                     0.622    0.03657                   0.050265   \n",
       "4                     0.575    0.05596                   0.033969   \n",
       "...                     ...        ...                        ...   \n",
       "2595                  0.655    0.03727                   0.020035   \n",
       "2596                  0.552    0.10080                   0.031689   \n",
       "2597                  0.745    0.07569                   0.032200   \n",
       "2598                  0.739    0.03438                   0.033659   \n",
       "2599                  0.652    0.01084                   0.022793   \n",
       "\n",
       "      Endpoints/Total Length  Average Fiber Length  Average Fiber Thickness  \\\n",
       "0                   0.017228             18.371560                14.656679   \n",
       "1                   0.025825             21.987382                16.011478   \n",
       "2                   0.022872             36.862745                28.829787   \n",
       "3                   0.018420             29.118182                19.419294   \n",
       "4                   0.022370             35.500000                23.819387   \n",
       "...                      ...                   ...                      ...   \n",
       "2595                0.024793             44.614525                16.403706   \n",
       "2596                0.021966             37.275168                19.877566   \n",
       "2597                0.016611             40.973822                19.039100   \n",
       "2598                0.014146             41.836735                18.024390   \n",
       "2599                0.012514             56.645570                14.569832   \n",
       "\n",
       "            cell_type  \n",
       "0                  L1  \n",
       "1                  L1  \n",
       "2                  L1  \n",
       "3                  L1  \n",
       "4                  L1  \n",
       "...               ...  \n",
       "2595  Reactive Lymphs  \n",
       "2596  Reactive Lymphs  \n",
       "2597  Reactive Lymphs  \n",
       "2598  Reactive Lymphs  \n",
       "2599  Reactive Lymphs  \n",
       "\n",
       "[2600 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell types: {'L2', 'Myeloblasts', 'Monoblasts', 'Reactive Lymphs', 'L3', 'L1'}\n"
     ]
    }
   ],
   "source": [
    "### summarize data\n",
    "# show dataframe\n",
    "display(combined_df)\n",
    "# show unique cell types\n",
    "print(\"Cell types:\", set(combined_df[\"cell_type\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4633e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct the data permutations\n",
    "# now make different combinations of the data\n",
    "# L1 and RL\n",
    "l1_and_rl_df = combined_df[combined_df[\"cell_type\"].isin([\"L1\", \"Reactive Lymphs\"])]\n",
    "# L2 and RL\n",
    "l2_and_rl_df = combined_df[combined_df[\"cell_type\"].isin([\"L2\", \"Reactive Lymphs\"])]\n",
    "# L3 and RL\n",
    "l3_and_rl_df = combined_df[combined_df[\"cell_type\"].isin([\"L3\", \"Reactive Lymphs\"])]\n",
    "# L1, L2, RL\n",
    "l1_and_l2_and_rl_df = combined_df[combined_df[\"cell_type\"].isin([\"L1\", \"L2\", \"Reactive Lymphs\"])]\n",
    "# Monoblast and RL\n",
    "monoblast_and_rl_df = combined_df[combined_df[\"cell_type\"].isin([\"Monoblasts\", \"Reactive Lymphs\"])]\n",
    "# Myeloblast and RL\n",
    "myeloblast_and_rl_df = combined_df[combined_df[\"cell_type\"].isin([\"Myeloblasts\", \"Reactive Lymphs\"])]\n",
    "# Combined blasts and RL\n",
    "combined_blasts_and_rl_df = combined_df.copy()\n",
    "combined_blasts_and_rl_df.loc[combined_df[\"cell_type\"] != \"Reactive Lymphs\", \"cell_type\"] = \"Blasts\"\n",
    "\n",
    "# save dataframes in a dictionary with keys as their labels\n",
    "list_of_df = [combined_df, l1_and_rl_df, l2_and_rl_df, l3_and_rl_df, l1_and_l2_and_rl_df, monoblast_and_rl_df, myeloblast_and_rl_df, combined_blasts_and_rl_df]\n",
    "list_of_df_names = [\"All Cells\", \"L1 and RL\", \"L2 and RL\", \"L3 and RL\", \"L1 and L2 and RL\", \"Monoblast and RL\", \"Myeloblast and RL\", \"All blasts and RL\"]\n",
    "dict_of_df = dict(zip(list_of_df_names, list_of_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b1089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define pipeline\n",
    "# first, scale the data with a standard scaler\n",
    "# then, reduce dimensionality with PCA (number of dimensions tbd in model selection)\n",
    "# finally, use either random forest or knn to classify (also tbd)\n",
    "# help from: https://scikit-learn.org/stable/auto_examples/compose/plot_compare_reduction.html#sphx-glr-auto-examples-compose-plot-compare-reduction-py\n",
    "\n",
    "# pass the selection of the classification algorithm through to validation\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaling\", StandardScaler()),\n",
    "        (\"reduce_dim\", PCA()),\n",
    "        (\"classify\", \"passthrough\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf260df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the parameter space to use during validation (model selection and hyperparameter optimization)\n",
    "param_dist = [\n",
    "    {   # Random Forest                                                             # options for...\n",
    "        \"classify\":                         [RandomForestClassifier()],             # model being trained (Random Forest)                                                             # options for...\n",
    "        \"reduce_dim__n_components\":         [2, 4, 8, None],                        # number of components to keep from PCA\n",
    "        \"classify__n_estimators\":           [30, 100, 300],                         # number of decision trees in the random forest\n",
    "        \"classify__max_depth\":              [10, 25, 50, None],                     # maximum allowed depth of the decision trees\n",
    "        \"classify__max_features\":           [\"sqrt\", \"log2\", None],                 # restriction on number of features considered per split\n",
    "        \"classify__bootstrap\":              [True, False],                          # whether to bootstrap\n",
    "        \"classify__min_samples_split\":      [2, 3, 4]                               # minimum number of samples required to split a node\n",
    "    },\n",
    "    {   # K nearest neighbors                                                       # options for...\n",
    "        \"classify\":                         [KNeighborsClassifier()],               # model being trained (K nearest neighbors)\n",
    "        \"reduce_dim__n_components\":         [2, 4, 8, None],                        # number of components to keep from PCA\n",
    "        \"classify__weights\":                [\"uniform\", \"distance\"],                # vote weighting method\n",
    "        \"classify__p\":                      [1, 1.25, 1.5, 1.75, 2, 2.25, 2.5],     # exponent parameter for minkowski distance\n",
    "        \"classify__n_neighbors\":            [3, 5, 7, 11, 15],                      # number of neighbors considered\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135d086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define custom model evaluation metrics\n",
    "def custom_success_metrics(y_test, y_pred, type):\n",
    "    # find confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # for each class, evaluate true positives, true negatives, etc (vectorized)\n",
    "    # Chat GPT helped here\n",
    "    tps = np.diag(cm)\n",
    "    fps = np.sum(cm, axis=0) - tps\n",
    "    fns = np.sum(cm, axis=1) - tps\n",
    "    tns = np.sum(cm) - (fps + fns + tps)\n",
    "    # each of these should be a vector with index corresponding to class\n",
    "    # now return a custom dictionary of balanced (macro-averaged) versions of accuracy, precision, sensitivity, specificity\n",
    "    # treat nan values as a score of 0, most likely are caused by empty classes\n",
    "    # also silence warnings caused by these issues during cv\n",
    "    # ChatGPT helped generate code to sanitize the final value and suppress warnings\n",
    "    val = None\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):            \n",
    "        match type:\n",
    "            case \"accuracy\": val = np.nanmean((tps + tns) / (tps + tns + fns + fps))\n",
    "            case \"precision\": val = np.nanmean(tps / (tps + fps))\n",
    "            case \"sensitivity\": val = np.nanmean(tps / (tps + fns))\n",
    "            case \"specificity\": val = np.nanmean(tns / (tns + fps))\n",
    "            case _: raise ValueError(f\"Type \\\"{type}\\\" is not supported\")\n",
    "    return 0.0 if np.isnan(val) else val\n",
    "\n",
    "# metrics to be calculated on each proposed model during cross validation (for model selection and hyperparameter optimization)\n",
    "metrics_dict = {\n",
    "    \"accuracy\": make_scorer(lambda ytest, ypred: custom_success_metrics(ytest, ypred, \"accuracy\")),\n",
    "    \"precision\": make_scorer(lambda ytest, ypred: custom_success_metrics(ytest, ypred, \"precision\")),\n",
    "    \"sensitivity\": make_scorer(lambda ytest, ypred: custom_success_metrics(ytest, ypred, \"sensitivity\")),\n",
    "    \"specificity\": make_scorer(lambda ytest, ypred: custom_success_metrics(ytest, ypred, \"specificity\")),\n",
    "    # use ovo because of class imbalance in some of the data permutations\n",
    "    \"auc_roc\": make_scorer(roc_auc_score, multi_class = \"ovo\", response_method=[\"decision_function\", \"predict_proba\"]),\n",
    "    \"f1\": \"f1_macro\"\n",
    "}\n",
    "\n",
    "# Also define by class for use in final testing\n",
    "def custom_success_metrics_by_class(y_test, y_pred, type):\n",
    "    # find confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # for each class, evaluate true positives, true negatives, etc (vectorized)\n",
    "    # Chat GPT helped to get these straight\n",
    "    tps = np.diag(cm)\n",
    "    fps = np.sum(cm, axis=0) - tps\n",
    "    fns = np.sum(cm, axis=1) - tps\n",
    "    tns = np.sum(cm) - (fps + fns + tps)\n",
    "    # each of these should be a vector with index corresponding to class\n",
    "    # now compute the vector for either accuracy, precision, sensitivity or specificity\n",
    "    val = None\n",
    "    match type:\n",
    "        case \"accuracy\": val = (tps + tns) / (tps + tns + fns + fps)\n",
    "        case \"precision\": val = tps / (tps + fps)\n",
    "        case \"sensitivity\": val = tps / (tps + fns)\n",
    "        case \"specificity\": val = tns / (tns + fps)\n",
    "        case _: raise ValueError(f\"Type \\\"{type}\\\" is not supported\")\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba17956",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define replicable train-test split\n",
    "def ttsplit(df):\n",
    "    # split the data stratified by cell type 70-30 for training-testing\n",
    "    # use a fixed random state so that each split can be replicated exactly\n",
    "    # our response variable is cell type\n",
    "    y_data = df[\"cell_type\"]\n",
    "    X_data = df.drop(\"cell_type\", axis=1, inplace=False)\n",
    "    # split our data points into 70-30 training and testing sets, stratified by cell type\n",
    "    # returns X_train, X_test, y_train, y_test\n",
    "    return train_test_split(X_data, y_data, test_size = 0.3, random_state=1234, shuffle=True, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b0e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomized Search CV on All blasts and RL data: 100%|██████████| 8/8 [31:57<00:00, 239.69s/it]\n"
     ]
    }
   ],
   "source": [
    "### Model validation and training\n",
    "# Perform random search for model selection and hyperparameter optimization\n",
    "# Run random search on the pipeline for each permutation of the dataset stored in dict_of_df\n",
    "# Save results for each model in a dictionary\n",
    "result_dicts = dict()\n",
    "# fit each of the data and test on the testing data\n",
    "pbar = tqdm(dict_of_df.items())\n",
    "for name, df in pbar:\n",
    "    # Identify which permutation is being run\n",
    "    pbar.set_description(f\"Randomized Search CV on {name} data\")\n",
    "    # record results for this specific permutation in results_dict\n",
    "    results_dict = dict()\n",
    "    # split the data (split can be replicated later, as a fixed random seed is used in ttsplit)\n",
    "    X_train, X_test, y_train, y_test = ttsplit(df)\n",
    "    # set up a randomized search on the pipeline using stratified 5-fold cross validation\n",
    "    # (default for training classifiers, but specifying here to be explicit and provide replicable random state)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    search = RandomizedSearchCV(pipe, n_iter=400, n_jobs=-1, param_distributions=param_dist, scoring=metrics_dict, refit='accuracy', cv=cv, verbose=False, error_score='raise')\n",
    "    # cross validate and then fit the data on the best estimator in terms of average cv-determined accuracy\n",
    "    search.fit(X_train, y_train)\n",
    "    # save the results, including the best estimator\n",
    "    results = pd.DataFrame(search.cv_results_)\n",
    "    results.sort_values(by=\"rank_test_accuracy\", inplace=True)\n",
    "    results_dict['results'] = results\n",
    "    results_dict['best_params'] = search.best_params_\n",
    "    results_dict['best_score'] = search.best_score_\n",
    "    results_dict['best_estimator'] = search.best_estimator_\n",
    "    result_dicts[name] = results_dict\n",
    "# save results of the random search and cv in a spreadsheet\n",
    "# write these dataframes to an excel sheet\n",
    "with pd.ExcelWriter(\"validation.xlsx\", engine='openpyxl') as writer:\n",
    "    for name, results in result_dicts.items():\n",
    "        results['results'].to_excel(writer, sheet_name=name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8dbcd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*All Cells*\n",
      "classes:\n",
      "['L1' 'L2' 'L3' 'Monoblasts' 'Myeloblasts' 'Reactive Lymphs']\n",
      "confusion matrix:\n",
      "[[101  12   0   1  14  10]\n",
      " [ 12  71  21  15  27  12]\n",
      " [  1  31  62   8  11   8]\n",
      " [  0  20  15  71   8   8]\n",
      " [ 24  30   3  10  49   9]\n",
      " [ 36   8   4  10  10  48]]\n",
      "accuracy by class: [0.85897436 0.75897436 0.86923077 0.87820513 0.81282051 0.8525641 ]\n",
      "average accuracy (balanced, by class): 0.8384615384615385\n",
      "precision by class: [0.58045977 0.4127907  0.59047619 0.6173913  0.41176471 0.50526316]\n",
      "average precision (balanced, by class): 0.5196909710650779\n",
      "sensitivity by class: [0.73188406 0.44936709 0.51239669 0.58196721 0.392      0.4137931 ]\n",
      "average sensitivity (balanced, by class): 0.5135680262260859\n",
      "specificity by class: [0.88629283 0.83762058 0.93474962 0.9331307  0.89312977 0.92921687]\n",
      "average specificity (balanced, by class): 0.9023567286428036\n",
      "AUC (OVO): 0.83854959551026\n",
      "Model details: \n",
      "{'reduce_dim__n_components': None, 'classify__n_estimators': 300, 'classify__min_samples_split': 4, 'classify__max_features': 'sqrt', 'classify__max_depth': 10, 'classify__bootstrap': True, 'classify': RandomForestClassifier()}\n",
      "\n",
      "\n",
      "\n",
      "*L1 and RL*\n",
      "classes:\n",
      "['L1' 'Reactive Lymphs']\n",
      "confusion matrix:\n",
      "[[115  23]\n",
      " [ 42  75]]\n",
      "accuracy by class: [0.74509804 0.74509804]\n",
      "average accuracy (balanced, by class): 0.7450980392156863\n",
      "precision by class: [0.73248408 0.76530612]\n",
      "average precision (balanced, by class): 0.7488950994410503\n",
      "sensitivity by class: [0.83333333 0.64102564]\n",
      "average sensitivity (balanced, by class): 0.7371794871794872\n",
      "specificity by class: [0.64102564 0.83333333]\n",
      "average specificity (balanced, by class): 0.7371794871794872\n",
      "AUC:  0.8160535117056856\n",
      "Model details: \n",
      "{'reduce_dim__n_components': None, 'classify__n_estimators': 100, 'classify__min_samples_split': 4, 'classify__max_features': 'log2', 'classify__max_depth': 25, 'classify__bootstrap': True, 'classify': RandomForestClassifier()}\n",
      "\n",
      "\n",
      "\n",
      "*L2 and RL*\n",
      "classes:\n",
      "['L2' 'Reactive Lymphs']\n",
      "confusion matrix:\n",
      "[[138  20]\n",
      " [ 25  92]]\n",
      "accuracy by class: [0.83636364 0.83636364]\n",
      "average accuracy (balanced, by class): 0.8363636363636363\n",
      "precision by class: [0.84662577 0.82142857]\n",
      "average precision (balanced, by class): 0.8340271691498685\n",
      "sensitivity by class: [0.87341772 0.78632479]\n",
      "average sensitivity (balanced, by class): 0.8298712539218869\n",
      "specificity by class: [0.78632479 0.87341772]\n",
      "average specificity (balanced, by class): 0.8298712539218869\n",
      "AUC:  0.8852645245050308\n",
      "Model details: \n",
      "{'reduce_dim__n_components': None, 'classify__n_estimators': 300, 'classify__min_samples_split': 3, 'classify__max_features': 'log2', 'classify__max_depth': None, 'classify__bootstrap': True, 'classify': RandomForestClassifier()}\n",
      "\n",
      "\n",
      "\n",
      "*L3 and RL*\n",
      "classes:\n",
      "['L3' 'Reactive Lymphs']\n",
      "confusion matrix:\n",
      "[[101  20]\n",
      " [ 16 101]]\n",
      "accuracy by class: [0.8487395 0.8487395]\n",
      "average accuracy (balanced, by class): 0.8487394957983193\n",
      "precision by class: [0.86324786 0.83471074]\n",
      "average precision (balanced, by class): 0.8489793035247581\n",
      "sensitivity by class: [0.83471074 0.86324786]\n",
      "average sensitivity (balanced, by class): 0.8489793035247581\n",
      "specificity by class: [0.86324786 0.83471074]\n",
      "average specificity (balanced, by class): 0.8489793035247581\n",
      "AUC:  0.9054178145087236\n",
      "Model details: \n",
      "{'reduce_dim__n_components': 8, 'classify__n_estimators': 300, 'classify__min_samples_split': 2, 'classify__max_features': 'sqrt', 'classify__max_depth': 10, 'classify__bootstrap': True, 'classify': RandomForestClassifier()}\n",
      "\n",
      "\n",
      "\n",
      "*L1 and L2 and RL*\n",
      "classes:\n",
      "['L1' 'L2' 'Reactive Lymphs']\n",
      "confusion matrix:\n",
      "[[106  19  13]\n",
      " [ 16 127  15]\n",
      " [ 35  29  53]]\n",
      "accuracy by class: [0.79903148 0.80871671 0.77723971]\n",
      "average accuracy (balanced, by class): 0.7949959644874899\n",
      "precision by class: [0.67515924 0.72571429 0.65432099]\n",
      "average precision (balanced, by class): 0.6850648363457988\n",
      "sensitivity by class: [0.76811594 0.80379747 0.45299145]\n",
      "average sensitivity (balanced, by class): 0.6749682877916229\n",
      "specificity by class: [0.81454545 0.81176471 0.90540541]\n",
      "average specificity (balanced, by class): 0.843905188611071\n",
      "AUC (OVO): 0.8529628244588802\n",
      "Model details: \n",
      "{'reduce_dim__n_components': None, 'classify__n_estimators': 300, 'classify__min_samples_split': 2, 'classify__max_features': 'log2', 'classify__max_depth': 10, 'classify__bootstrap': True, 'classify': RandomForestClassifier()}\n",
      "\n",
      "\n",
      "\n",
      "*Monoblast and RL*\n",
      "classes:\n",
      "['Monoblasts' 'Reactive Lymphs']\n",
      "confusion matrix:\n",
      "[[101  21]\n",
      " [ 19  97]]\n",
      "accuracy by class: [0.83193277 0.83193277]\n",
      "average accuracy (balanced, by class): 0.8319327731092437\n",
      "precision by class: [0.84166667 0.8220339 ]\n",
      "average precision (balanced, by class): 0.8318502824858758\n",
      "sensitivity by class: [0.82786885 0.8362069 ]\n",
      "average sensitivity (balanced, by class): 0.8320378745053703\n",
      "specificity by class: [0.8362069  0.82786885]\n",
      "average specificity (balanced, by class): 0.8320378745053703\n",
      "AUC:  0.9039358394573206\n",
      "Model details: \n",
      "{'reduce_dim__n_components': None, 'classify__n_estimators': 100, 'classify__min_samples_split': 3, 'classify__max_features': 'log2', 'classify__max_depth': None, 'classify__bootstrap': True, 'classify': RandomForestClassifier()}\n",
      "\n",
      "\n",
      "\n",
      "*Myeloblast and RL*\n",
      "classes:\n",
      "['Myeloblasts' 'Reactive Lymphs']\n",
      "confusion matrix:\n",
      "[[106  19]\n",
      " [ 30  87]]\n",
      "accuracy by class: [0.79752066 0.79752066]\n",
      "average accuracy (balanced, by class): 0.7975206611570248\n",
      "precision by class: [0.77941176 0.82075472]\n",
      "average precision (balanced, by class): 0.8000832408435072\n",
      "sensitivity by class: [0.848      0.74358974]\n",
      "average sensitivity (balanced, by class): 0.7957948717948717\n",
      "specificity by class: [0.74358974 0.848     ]\n",
      "average specificity (balanced, by class): 0.7957948717948717\n",
      "AUC:  0.864068376068376\n",
      "Model details: \n",
      "{'reduce_dim__n_components': None, 'classify__n_estimators': 300, 'classify__min_samples_split': 2, 'classify__max_features': 'sqrt', 'classify__max_depth': 10, 'classify__bootstrap': True, 'classify': RandomForestClassifier()}\n",
      "\n",
      "\n",
      "\n",
      "*All blasts and RL*\n",
      "classes:\n",
      "['Blasts' 'Reactive Lymphs']\n",
      "confusion matrix:\n",
      "[[644  20]\n",
      " [ 88  28]]\n",
      "accuracy by class: [0.86153846 0.86153846]\n",
      "average accuracy (balanced, by class): 0.8615384615384616\n",
      "precision by class: [0.87978142 0.58333333]\n",
      "average precision (balanced, by class): 0.7315573770491803\n",
      "sensitivity by class: [0.96987952 0.24137931]\n",
      "average sensitivity (balanced, by class): 0.6056294142085583\n",
      "specificity by class: [0.24137931 0.96987952]\n",
      "average specificity (balanced, by class): 0.6056294142085583\n",
      "AUC:  0.8388229642708765\n",
      "Model details: \n",
      "{'reduce_dim__n_components': None, 'classify__n_estimators': 100, 'classify__min_samples_split': 3, 'classify__max_features': None, 'classify__max_depth': None, 'classify__bootstrap': True, 'classify': RandomForestClassifier()}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Model testing\n",
    "# Test best performing models and report output in human readable format\n",
    "# Iterate through each permutation of the data (all cells, L1 vs RL, etc)\n",
    "for name, results_dict in result_dicts.items():\n",
    "    # get the best model found for the permutation given judging by accuracy\n",
    "    # these were manually confirmed in model validation to have acceptable values for the other evaluation metrics during cross validation\n",
    "    best_estimator = results_dict['best_estimator']\n",
    "    # identify whether this is a multi-class situation\n",
    "    is_multi_class = True if len(best_estimator.classes_) > 2 else False\n",
    "    # recreate the train and test split (ttsplit uses random seed so the split will be identical to split used in training)\n",
    "    _, X_test, __, y_test = ttsplit(dict_of_df[name])\n",
    "    # find model predicted values and probabilities on the testing data\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "    y_prob = best_estimator.predict_proba(X_test)\n",
    "    # generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, normalize=None)\n",
    "    # output the evaluation metrics in a human-readable format\n",
    "    # specify which data permutation we are using\n",
    "    print(f'*{name}*')\n",
    "    # record class order and the confusion matrix as calculated for the test data\n",
    "    print('classes:', best_estimator.classes_, sep='\\n')\n",
    "    print('confusion matrix:', cm, sep='\\n')\n",
    "    # evaluate and report model accuracy, precision, sensitivity, specificity\n",
    "    for metric in ['accuracy', 'precision', 'sensitivity', 'specificity']:\n",
    "        met_vals = custom_success_metrics_by_class(y_test, y_pred, metric)\n",
    "        print(f'{metric} by class:', met_vals)\n",
    "        print(f'average {metric} (balanced, by class):', np.mean(met_vals), sep=' ')\n",
    "    # evaluate Area Under the Curve\n",
    "    # use one-vs-one strategy for multi-class situations\n",
    "    if is_multi_class:\n",
    "        print('AUC (OVO):', roc_auc_score(y_test, y_prob, multi_class='ovo'))\n",
    "    else:\n",
    "        print('AUC: ', roc_auc_score(y_test, y_prob[:,1]))\n",
    "    # record the model parameters\n",
    "    print(\"Model details: \")\n",
    "    print(results_dict['best_params'])\n",
    "    print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
